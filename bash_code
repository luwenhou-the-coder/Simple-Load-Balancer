MySQL part:

mysql -h project3-4.cchoqihkcvdv.us-east-1.rds.amazonaws.com --local-infile -u wenhoulu -p

create table users(u_id varchar(15), pwd varchar(50), primary key(u_id));
create table userinfo(u_id varchar(15), name varchar(50), url text, primary key(u_id));
ALTER DATABASE project34 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_unicode_ci;
ALTER TABLE userinfo CONVERT TO CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;
ALTER TABLE userinfo DEFAULT CHARACTER SET utf8mb4, MODIFY u_id VARCHAR(15) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci NOT NULL, MODIFY name VARCHAR(50) CHARACTER SET utf8mb4 COLLATE utf8mb4_bin NOT NULL, MODIFY url TEXT CHARACTER SET utf8mb4 COLLATE utf8mb4_bin NOTNULL;


LOAD DATA LOCAL INFILE '/home/ubuntu/users.csv' INTO TABLE users FIELDS TERMINATED BY ',' LINES TERMINATED BY '\n';
LOAD DATA LOCAL INFILE '/home/ubuntu/userinfo.csv' INTO TABLE userinfo FIELDS TERMINATED BY ',' LINES TERMINATED BY '\n';


HBase part:

awk -F"," 'BEGIN { OFS = "," } {$3=$2;$2=$1;$1=$2"f"$3; print}' links.csv > newlinks.csv

create 'userlink','follow'

hbase org.apache.hadoop.hbase.mapreduce.ImportTsv -Dimporttsv.columns=HBASE_ROW_KEY,follow:followee,follow:followers  '-Dimporttsv.separator=,' -Dimporttsv.bulk.output=/storefileoutput userlink /p34/newlinks.csv

hbase org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles /storefileoutput/ userlink

